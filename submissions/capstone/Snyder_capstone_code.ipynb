{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Book Rating Predictor\n",
    "\n",
    "Online services such as Amazon and Netflix make extensive use of prediction algorithms to give users new product recommendations. While these systems can make reasonable predictions just using simple means for items or users, they can give much more accurate predicitons by taking into account the relationships between items and users. Essentially, finding correlations between similar items and users in order to determine what users will rank an item the highest.\n",
    "\n",
    "Several algorithms are used to build these rating systems, but what is their relative performance? How much advantage is there in using an autoencoder versus a simple linear model? This project explores the relative performance of five different recommendation algorithms, linear regression, cosine similarity, singular value decomposition, restricted Boltzmann machines, and autoencoders.\n",
    "\n",
    "## Data\n",
    "\n",
    "The data used for this project was collected by Julian McAuley as the University of California San Diego, and is available [here](http://jmcauley.ucsd.edu/data/amazon/). This project focuses only on book reviews. I also restrict my analysis to the 5-core data, which is users who have reviewed at least 5 items. This restriction helps avoid some of the more complex issues of dealing with highly sparse matrices.\n",
    "\n",
    "## Performance Measure\n",
    "\n",
    "While the ratings take integer values for each individual observation, they can be considered a continuous measure between 1 and 5. Therefore, I use a standard measure of accuracy, root mean squared error.\n",
    "\n",
    "## Data Preparation\n",
    "\n",
    "Each algorithm will need the data in a slightly different format. The original format is a single large json file. So I start by reformatting the data in something easier to work with.\n",
    "\n",
    "I use Dask to quickly read the json file, and convert it into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use dask to efficiently read the json file\n",
    "from dask import bag\n",
    "from dask.diagnostics import ProgressBar\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'asin': '000100039X',\n",
       "  'helpful': [0, 0],\n",
       "  'overall': 5.0,\n",
       "  'reviewText': 'Spiritually and mentally inspiring! A book that allows you to question your morals and will help you discover who you really are!',\n",
       "  'reviewTime': '12 16, 2012',\n",
       "  'reviewerID': 'A10000012B7CGYKOMPQ4L',\n",
       "  'reviewerName': 'Adam',\n",
       "  'summary': 'Wonderful!',\n",
       "  'unixReviewTime': 1355616000},\n",
       " {'asin': '000100039X',\n",
       "  'helpful': [0, 2],\n",
       "  'overall': 5.0,\n",
       "  'reviewText': \"This is one my must have books. It is a masterpiece of spirituality. I'll be the first to admit, its literary quality isn't much. It is rather simplistically written, but the message behind it is so powerful that you have to read it. It will take you to enlightenment.\",\n",
       "  'reviewTime': '12 11, 2003',\n",
       "  'reviewerID': 'A2S166WSCFIFP5',\n",
       "  'reviewerName': 'adead_poet@hotmail.com \"adead_poet@hotmail.com\"',\n",
       "  'summary': 'close to god',\n",
       "  'unixReviewTime': 1071100800},\n",
       " {'asin': '000100039X',\n",
       "  'helpful': [0, 0],\n",
       "  'overall': 5.0,\n",
       "  'reviewText': 'This book provides a reflection that you can apply to your own life.And, a way for you to try and assess whether you are truly doing the right thing and making the most of your short time on this plane.',\n",
       "  'reviewTime': '01 18, 2014',\n",
       "  'reviewerID': 'A1BM81XB4QHOA3',\n",
       "  'reviewerName': 'Ahoro Blethends \"Seriously\"',\n",
       "  'summary': 'Must Read for Life Afficianados',\n",
       "  'unixReviewTime': 1390003200},\n",
       " {'asin': '000100039X',\n",
       "  'helpful': [0, 0],\n",
       "  'overall': 5.0,\n",
       "  'reviewText': \"I first read THE PROPHET in college back in the 60's. The book had a revival as did anything metaphysical in the turbulent 60's. It had a profound effect on me and became a book I always took with me. After graduation I joined the Peace Corps and during stressful training in country (Liberia) at times of illness and the night before I left, this book gave me great comfort. I read it before I married, just before and again after my children were born and again after two near fatal illnesses. I am always amazed that there is a chapter that reaches out to you, grabs you and offers both comfort and hope for the future.Gibran offers timeless insights and love with each word. I think that we as a nation should read AND learn the lessons here. It is definitely a time for thought and reflection this book could guide us through.\",\n",
       "  'reviewTime': '09 27, 2011',\n",
       "  'reviewerID': 'A1MOSTXNIO5MPJ',\n",
       "  'reviewerName': 'Alan Krug',\n",
       "  'summary': 'Timeless for every good and bad time in your life.',\n",
       "  'unixReviewTime': 1317081600},\n",
       " {'asin': '000100039X',\n",
       "  'helpful': [7, 9],\n",
       "  'overall': 5.0,\n",
       "  'reviewText': 'A timeless classic.  It is a very demanding and assuming title, but Gibran backs it up with some excellent style and content.  If he had the means to publish it a century or two earlier, he could have inspired a new religion.From the mouth of an old man about to sail away to a far away destination, we hear the wisdom of life and all important aspects of it.  It is a messege.  A guide book.  A Sufi sermon. Much is put in perspective without any hint of a dogma.  There is much that hints at his birth place, Lebanon where many of the old prophets walked the Earth and where this book project first germinated most likely.Probably becuase it was written in English originally, the writing flows, it is pleasant to read, and the charcoal drawings of the author decorating the pages is a plus.  I loved the cover.',\n",
       "  'reviewTime': '10 7, 2002',\n",
       "  'reviewerID': 'A2XQ5LZHTD4AFT',\n",
       "  'reviewerName': 'Alaturka',\n",
       "  'summary': 'A Modern Rumi',\n",
       "  'unixReviewTime': 1033948800})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "js = bag.read_text('input/reviews_Books_5.json.gz').map(json.loads)\n",
    "js.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  4min 17.1s\n",
      "[########################################] | 100% Completed |  4min 18.3s\n",
      "[########################################] | 100% Completed |  3min 46.9s\n"
     ]
    }
   ],
   "source": [
    "# load json data as a dask bag\n",
    "js = bag.read_text('input/reviews_Books_5.json.gz').map(json.loads)\n",
    "# convert each variable of interest into an array to add to a dataframe\n",
    "asin = js.pluck('asin')\n",
    "reviewerID = js.pluck('reviewerID')\n",
    "overall = js.pluck('overall')\n",
    "# convert to pandas dataframe, this line will take a few minutes\n",
    "with ProgressBar():\n",
    "    ratings_df = pd.DataFrame({'asin':asin.compute(), \n",
    "                               'reviewerID':reviewerID.compute(), \n",
    "                               'overall':overall.compute()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ratings_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-95a8d0ae0567>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# take a look at the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mratings_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ratings_df' is not defined"
     ]
    }
   ],
   "source": [
    "# take a look at the data\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because I'll need to make these ratings into a sparse matrix, it's easiest to convert the data into all numeric values. I then save the dataframe to a csv file so that when I need to load the data in again later, I don't have to read the json files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the asin and reviewerID for use with sparse matrices later\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "item_le = LabelEncoder()\n",
    "item_le.fit(ratings_df['asin'])\n",
    "reviewer_le = LabelEncoder()\n",
    "reviewer_le.fit(ratings_df['reviewerID'])\n",
    "ratings_num_df = pd.DataFrame({'asin':item_le.transform(ratings_df['asin']),\n",
    "                               'reviewerID':reviewer_le.transform(ratings_df['reviewerID']),\n",
    "                               'rating':ratings_df['overall']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>284567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>52489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>101774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>310083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   asin  rating  reviewerID\n",
       "0     0     5.0         551\n",
       "1     0     5.0      284567\n",
       "2     0     5.0       52489\n",
       "3     0     5.0      101774\n",
       "4     0     5.0      310083"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save this file to make loading faster in the future\n",
    "#ratings_num_df.to_csv('input/ratings_long.csv', index = False)\n",
    "\n",
    "ratings_num_df = pd.read_csv('input/ratings_long.csv')\n",
    "ratings_num_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.hist(ratings_num_df['rating'], bins = 5)\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of user ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    0.559765\n",
       "4.0    0.249841\n",
       "3.0    0.107348\n",
       "2.0    0.046652\n",
       "1.0    0.036394\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_num_df['rating'].value_counts()/len(ratings_num_df['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuoAAAHwCAYAAADwwkrGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAIABJREFUeJzt3Xu4ded8L/zvTyLOBAk7EjwpoYLtFEQpEd3EMarsVxqkdkp361Q9Ce2utqk2Xofi3dhVVNQhsqMXQTRSJKluciBOoXaCkDQhISIRhCS/9485nlpW1lrPymE+617P+nyua11zjHvcY9y/ObOuPN95r3uOWd0dAABgLNdb6wIAAICrEtQBAGBAgjoAAAxIUAcAgAEJ6gAAMCBBHQAABiSoAxteVZ1eVfusdR1rqap+tarOrqofVNV95jzWS6rqzfMcY4Wx31ZVf7kWYwNcXYI6sE2rqrOq6lcWtf1GVX1i83533727j9/CdTZVVVfV9nMqda29Mslzu/um3X3aPAfq7r/q7t+c5xgA2wJBHWAAA7wBuGOS01fTcYBaN4yq2m6tawDWjqAObHgLZ92r6gFVdWpVXVxV366qV0/dTpweL5qWhzyoqq5XVX9SVd+oqvOr6u1VdYsF133GdOy7VfU/Fo3zZ1V1VFW9o6ouTvIb09ifrKqLquq8qvqfVbXDgut1Vf1OVZ1RVZdU1aFVdafpnIur6siF/Rc9xyVrraobVNUPkmyX5HNV9dVlzu+qek5VnZHkjKntF6vquKq6sKq+UlX/dWrfu6q+tTBkTktrPr/gub9jwbG9q+r/TM/7c5uXIVXVw6vqCwv6/XNVnbxg/xNV9cRp+0VV9e/T6/KVqnrECv/Jd5rqvqSqTqiqO07XeH1VvWrR8/5AVf3uEq/HVf7CUlXHV9VvTtt3nq79/ar6TlW9Z0G/JV+36djbquqNVXVMVV2a5OErPA9gGyeoA/y81yZ5bXffPMmdkhw5tT90etxxWh7yySS/Mf08PMkvJLlpkv+ZJFW1Z5I3JDkwyS5JbpFk10Vj7Z/kqCQ7JnlnkiuSvDDJTkkelOQRSX5n0Tn7Jblfkr2T/FGSN01j3D7JPZIcsMzzWrLW7r6su2869blXd99p+ZcmT0zywCR7VtVNkhyX5F1JbjON+4aqunt3fyrJpUn2XXDur099f05V7ZrkQ0n+MsmtkvxBkvdW1c5JPpnkzlW10xSI75Fkt6q6WVXdaHod/qWq7prkuUnu3903S/KoJGet8DwOTHJoZq/zZzN77ZPk8CQHVNX1ptp2yuy/wbtXuNZyDk3ykSS3TLJbkv9vuuayr9uCc389ycuS3CzJJwJsWII6sBG8b5qtvaiqLsosQC/np5nCYXf/YAqdyzkwyau7+2vd/YMkL07y1ClUPjnJB7r7E939kyR/mqQXnf/J7n5fd1/Z3T/q7k9396e6+/LuPivJ3yZ52KJzXt7dF3f36Um+mOQj0/jfT/LhJMt9EHSlWlfrr7v7wu7+UZLHJTmru/9+qvczSd47Pe9kFm4PSJKqulmSx2TpwPu0JMd09zHT63BcklOTPKa7fzxtPzTJXkk+n1lwfXBmb1TO6O7vZvYG5waZvYG4fnef1d1L/mVg8qHuPrG7L0vyx0keVFW37+6Tk3w/s3CeJE9Ncnx3f/tqvEab/TSz5US36+4fd/fmwL2l1y1J3t/d/zq9Hj++BmMD2whBHdgIntjdO27+yVVnqRc6OMldkvxbVZ1SVY9boe/tknxjwf43kmyf5LbTsbM3H+juHyb57qLzz164U1V3qaoPTstGLk7yV5nN+i60MDT+aIn9m2ZpK9W6WgvrvWOSBy56A3Rgkv80HX9XkidV1Q2SPCnJZ7r7G7mqOyZ5yqLrPCSzv0IkyQlJ9sksrJ+Q5PjM3rw8bNpPd5+Z5HeT/FmS86vqiKq63Wqex/Sm5cLMXp9kNqv+tGn7aUn+YYXrrOSPklSSk2t2V6H/tuD5rvS6/Vx9wMbmA0EAC3T3GfnZ8ocnJTmqqm6dq86GJ8m5mQWvze6Q5PLMwvN5Se66+cC0VOPWi4dbtP/GJKclOaC7L5nWRj85142Val2thfWeneSE7v4vS3bs/lJVfSPJo7PMspcF1/mH7n7WMsdPSPKqJN9McliS7yX5uySXJXn9gvHeleRdVXXzzP4S8fIkT1/mmrffvFFVN81syc25U9M7knyxqu6V5G5J3rfMNS6dHm+c5OJp+z/Cdnd/K8mzpjEekuSfq+rEbOF123z6CseADcSMOsACVfW0qtq5u69MctHUfEWSC5Jcmdn67s3eneSFVbX7FPj+Ksl7uvvyzNaeP76qfqlmH/D888xmWFdys8xC3w+q6heT/PZ19sRWrvWa+GCSu1TV06vq+tPP/avqbgv6vCvJ8zObDf/fy1znHZm9To+qqu2q6oZVtU9V7TYd/z+ZveF5QJKTpyU/d8xsrfyJSVJVd62qfafZ+x9n9peFK1ao/TFV9ZDpv8uhSU7q7rOTpLvPSXJKZjPp752W+VxFd1+Q5N+TPG2q+79l9pmGTDU9ZcFz+F5m4fuKVb5uAEkEdYDF9ktyes3uhPLaJE+d1hj/MLMP+P3rtGRh7yRvzSzQnZjk65mFxOclyRQon5fkiMxm1y9Jcn5mM8HL+YPMZp8vyWzW+D0r9L26lq31mujuS5I8MrN13Ocm+VZms9g3WNDt3ZktW/lYd39nmeucndmHal+S2Zuhs5P8YaZ/n7r70iSfSXL6tNY/mX3I9Bvdff60f4PMZtu/M9Vxm+l6y3lXkpdmtuTlfpktPVno8CT3zJaXvTxrqvW7Se6e2ZuKze6f5KTp9+joJC/o7q+v8nUDSJJUt7+wAczbNIt9UZI9uvvra10Py6uqh2Y2079p+ssKwJowow4wJ1X1+Kq68XRLvlcm+UJWvm0ga6yqrp/kBUneLKQDa01QB5if/TNb3nBukj0yW0bjz5iDmtaJX5TZHWdes8blAFj6AgAAIzKjDgAAAxLUAQBgQL7waLLTTjv1pk2b1roMAAC2YZ/+9Ke/0907r6avoD7ZtGlTTj311LUuAwCAbdj0rc2rYukLAAAMSFAHAIABCeoAADAgQR0AAAYkqAMAwIAEdQAAGJCgDgAAAxLUAQBgQII6AAAMSFAHAIABCeoAADAgQR0AAAYkqAMAwIAEdQAAGJCgDgAAAxLUAQBgQII6AAAMSFAHAIABCeoAADCg7de6gI1u0yEfWusStrqzDnvsWpcAADA8M+oAADAgQR0AAAYkqAMAwIAEdQAAGJCgDgAAAxLUAQBgQII6AAAMSFAHAIABCeoAADAgQR0AAAYkqAMAwIAEdQAAGJCgDgAAAxLUAQBgQII6AAAMSFAHAIABCeoAADAgQR0AAAYkqAMAwIAEdQAAGJCgDgAAAxLUAQBgQII6AAAMSFAHAIABCeoAADAgQR0AAAYkqAMAwIAEdQAAGJCgDgAAA5p7UK+q7arqtKr64LS/e1WdVFVnVNV7qmqHqf0G0/6Z0/FNC67x4qn9K1X1qAXt+01tZ1bVIQvalxwDAADWi60xo/6CJF9esP/yJH/T3Xsk+V6Sg6f2g5N8r7vvnORvpn6pqj2TPDXJ3ZPsl+QNU/jfLsnrkzw6yZ5JDpj6rjQGAACsC3MN6lW1W5LHJnnztF9J9k1y1NTl8CRPnLb3n/YzHX/E1H//JEd092Xd/fUkZyZ5wPRzZnd/rbt/kuSIJPtvYQwAAFgX5j2j/pokf5Tkymn/1kku6u7Lp/1zkuw6be+a5OwkmY5/f+r/H+2LzlmufaUxfk5VPbuqTq2qUy+44IJr+hwBAOA6N7egXlWPS3J+d396YfMSXXsLx66r9qs2dr+pu/fq7r123nnnpboAAMCa2H6O135wkidU1WOS3DDJzTObYd+xqrafZrx3S3Lu1P+cJLdPck5VbZ/kFkkuXNC+2cJzlmr/zgpjAADAujC3GfXufnF379bdmzL7MOjHuvvAJB9P8uSp20FJ3j9tHz3tZzr+se7uqf2p011hdk+yR5KTk5ySZI/pDi87TGMcPZ2z3BgAALAurMV91F+U5Peq6szM1pO/ZWp/S5JbT+2/l+SQJOnu05McmeRLSf4pyXO6+4pptvy5SY7N7K4yR059VxoDAADWhXkuffkP3X18kuOn7a9ldseWxX1+nOQpy5z/siQvW6L9mCTHLNG+5BgAALBe+GZSAAAYkKAOAAADEtQBAGBAgjoAAAxIUAcAgAEJ6gAAMCBBHQAABiSoAwDAgAR1AAAYkKAOAAADEtQBAGBAgjoAAAxIUAcAgAEJ6gAAMCBBHQAABiSoAwDAgAR1AAAYkKAOAAADEtQBAGBAgjoAAAxIUAcAgAEJ6gAAMCBBHQAABiSoAwDAgAR1AAAYkKAOAAADEtQBAGBAgjoAAAxIUAcAgAEJ6gAAMCBBHQAABiSoAwDAgAR1AAAYkKAOAAADEtQBAGBAgjoAAAxIUAcAgAEJ6gAAMCBBHQAABiSoAwDAgAR1AAAYkKAOAAADEtQBAGBAgjoAAAxIUAcAgAEJ6gAAMCBBHQAABiSoAwDAgAR1AAAYkKAOAAADEtQBAGBAgjoAAAxIUAcAgAEJ6gAAMCBBHQAABiSoAwDAgAR1AAAYkKAOAAADEtQBAGBAgjoAAAxIUAcAgAEJ6gAAMCBBHQAABiSoAwDAgAR1AAAYkKAOAAADEtQBAGBAgjoAAAxIUAcAgAEJ6gAAMCBBHQAABiSoAwDAgAR1AAAYkKAOAAADEtQBAGBAgjoAAAxIUAcAgAEJ6gAAMCBBHQAABiSoAwDAgAR1AAAYkKAOAAADEtQBAGBAgjoAAAxIUAcAgAEJ6gAAMKC5BfWqumFVnVxVn6uq06vqz6f23avqpKo6o6reU1U7TO03mPbPnI5vWnCtF0/tX6mqRy1o329qO7OqDlnQvuQYAACwXsxzRv2yJPt2972S3DvJflW1d5KXJ/mb7t4jyfeSHDz1PzjJ97r7zkn+ZuqXqtozyVOT3D3JfkneUFXbVdV2SV6f5NFJ9kxywNQ3K4wBAADrwtyCes/8YNq9/vTTSfZNctTUfniSJ07b+0/7mY4/oqpqaj+iuy/r7q8nOTPJA6afM7v7a939kyRHJNl/Ome5MQAAYF2Y6xr1aeb7s0nOT3Jckq8muai7L5+6nJNk12l71yRnJ8l0/PtJbr2wfdE5y7XfeoUxAABgXZhrUO/uK7r73kl2y2wG/G5LdZsea5lj11X7VVTVs6vq1Ko69YILLliqCwAArImtcteX7r4oyfFJ9k6yY1VtPx3aLcm50/Y5SW6fJNPxWyS5cGH7onOWa//OCmMsrutN3b1Xd++18847X5unCAAA16l53vVl56racdq+UZJfSfLlJB9P8uSp20FJ3j9tHz3tZzr+se7uqf2p011hdk+yR5KTk5ySZI/pDi87ZPaB06Onc5YbAwAA1oXtt9zlGtslyeHT3Vmul+TI7v5gVX0pyRFV9ZdJTkvylqn/W5L8Q1WdmdlM+lOTpLtPr6ojk3wpyeVJntPdVyRJVT03ybFJtkvy1u4+fbrWi5YZAwAA1oW5BfXu/nyS+yzR/rXM1qsvbv9xkqcsc62XJXnZEu3HJDlmtWMAAMB64ZtJAQBgQII6AAAMSFAHAIABCeoAADAgQR0AAAYkqAMAwIAEdQAAGJCgDgAAAxLUAQBgQII6AAAMSFAHAIABCeoAADAgQR0AAAYkqAMAwIAEdQAAGJCgDgAAAxLUAQBgQII6AAAMSFAHAIABCeoAADAgQR0AAAYkqAMAwIC2GNSr6k5VdYNpe5+qen5V7Tj/0gAAYONazYz6e5NcUVV3TvKWJLsneddcqwIAgA1uNUH9yu6+PMmvJnlNd78wyS7zLQsAADa21QT1n1bVAUkOSvLBqe368ysJAABYTVB/ZpIHJXlZd3+9qnZP8o75lgUAABvb9isdrKrtkryku5+2ua27v57ksHkXBgAAG9mKM+rdfUWSnatqh61UDwAAkC3MqE/OSvKvVXV0kks3N3b3q+dVFAAAbHSrCernTj/XS3Kz+ZYDAAAkqwjq3f3nSVJVN+nuS7fUHwAAuPZW882kD6qqLyX58rR/r6p6w9wrAwCADWw1t2d8TZJHJfluknT355I8dJ5FAQDARreaoJ7uPntR0xVzqAUAAJis5sOkZ1fVLyXp6TaNz8+0DAYAAJiP1cyo//ckz0mya5Jzktx72gcAAOZkNXd9+U6SA7dCLQAAwGQ1d335f6vq5lV1/ar6aFV9p6qetjWKAwCAjWo1S18e2d0XJ3lcZktf7pLkD+daFQAAbHCrCerXnx4fk+Td3X3hHOsBAACyuru+fKCq/i3Jj5L8TlXtnOTH8y0LAAA2ti3OqHf3IUkelGSv7v5pkh8m2X/ehQEAwEa27Ix6VT1pUVNX1XeSfLa7vzXfsgAAYGNbaenL45dou1WS/1xVB3f3x+ZUEwAAbHjLBvXufuZS7VV1xyRHJnngvIoCAICNbjV3ffk53f2N/OxOMAAAwBxc7aBeVXdNctkcagEAACYrfZj0A0l6UfOtkuySxDeTAgDAHK30YdJXLtrvJN9NckZ3/2R+JQEAACt9mPSErVkIAADwM1d7jToAADB/gjoAAAxo2aBeVR+dHl++9coBAACSlT9MuktVPSzJE6rqiCS18GB3f2aulQEAwAa2UlD/0ySHJNktyasXHesk+86rKAAA2OhWuuvLUUmOqqr/0d2HbsWaAABgw1tpRj1J0t2HVtUTkjx0ajq+uz8437IAAGBj2+JdX6rqr5O8IMmXpp8XTG0AAMCcbHFGPcljk9y7u69Mkqo6PMlpSV48z8IAAGAjW+191HdcsH2LeRQCAAD8zGpm1P86yWlV9fHMbtH40JhNBwCAuVrNh0nfXVXHJ7l/ZkH9Rd39rXkXBgAAG9lqZtTT3eclOXrOtQAAAJPVrlEHAAC2IkEdAAAGtGJQr6rrVdUXt1YxAADAzIpBfbp3+ueq6g5bqR4AACCr+zDpLklOr6qTk1y6ubG7nzC3qgAAYINbTVD/87lXAQAA/JzV3Ef9hKq6Y5I9uvufq+rGSbabf2kAALBxbfGuL1X1rCRHJfnbqWnXJO+bZ1EAALDRreb2jM9J8uAkFydJd5+R5DbzLAoAADa61QT1y7r7J5t3qmr7JD2/kgAAgNUE9ROq6iVJblRV/yXJ/07ygfmWBQAAG9tqgvohSS5I8oUkv5XkmCR/Ms+iAABgo1vNXV+urKrDk5yU2ZKXr3S3pS8AADBHWwzqVfXYJP8ryVeTVJLdq+q3uvvD8y4OAAA2qtV84dGrkjy8u89Mkqq6U5IPJRHUAQBgTlazRv38zSF98rUk58+pHgAAICvMqFfVk6bN06vqmCRHZrZG/SlJTtkKtQEAwIa10tKXxy/Y/naSh03bFyS55dwqAgAAlg/q3f3MrVkIAADwM6u568vuSZ6XZNPC/t39hPmVBQAAG9tq7vryviRvyezbSK+cbzkAAECyuqD+4+5+3dwrAQAA/sNqbs/42qp6aVU9qKruu/lnSydV1e2r6uNV9eWqOr2qXjC136qqjquqM6bHW07tVVWvq6ozq+rzC8eoqoOm/mdU1UEL2u9XVV+YznldVdVKYwAAwHqxmqB+zyTPSnJYZl9+9Kokr1zFeZcn+f3uvluSvZM8p6r2THJIko929x5JPjrtJ8mjk+wx/Tw7yRuTWehO8tIkD0zygCQvXRC83zj13XzeflP7cmMAAMC6sJqlL7+a5Be6+ydX58LdfV6S86btS6rqy0l2TbJ/kn2mbocnOT7Ji6b2t3d3J/lUVe1YVbtMfY/r7guTpKqOS7JfVR2f5Obd/cmp/e1JnpjZN6YuNwYAAKwLq5lR/1ySHa/NIFW1Kcl9kpyU5LZTiN8c5m8zdds1ydkLTjtnalup/Zwl2rPCGAAAsC6sZkb9tkn+rapOSXLZ5sbV3p6xqm6a5L1Jfre7L56WkS/ZdYm2vgbtq1ZVz85s6UzucIc7XJ1TAQBgrlYT1F96TS9eVdfPLKS/s7v/cWr+dlXt0t3nTUtbzp/az0ly+wWn75bk3Kl9n0Xtx0/tuy3Rf6Uxfk53vynJm5Jkr732ulohHwAA5mmLS1+6+4SlfrZ03nQHlrck+XJ3v3rBoaOTbL5zy0FJ3r+g/RnT3V/2TvL9adnKsUkeWVW3nD5E+sgkx07HLqmqvaexnrHoWkuNAQAA68Jqvpn0kvxsSckOSa6f5NLuvvkWTn1wkqcn+UJVfXZqe0lmd485sqoOTvLNJE+Zjh2T5DFJzkzywyTPTJLuvrCqDk1yytTvLzZ/sDTJbyd5W5IbZfYh0g9P7cuNAQAA68IWg3p332zhflU9MbPbJG7pvE9k6XXkSfKIJfp3kucsc623JnnrEu2nJrnHEu3fXWoMAABYL1Zz15ef093vS7LvHGoBAAAmq1n68qQFu9dLsleu5t1VAACAq2c1d315/ILty5OcldkXCgEAAHOymjXqz9wahQAAAD+zbFCvqj9d4bzu7kPnUA8AAJCVZ9QvXaLtJkkOTnLrJII6AADMybJBvbtftXm7qm6W5AWZ3dv8iCSvWu48AADg2ltxjXpV3SrJ7yU5MMnhSe7b3d/bGoUBAMBGttIa9VckeVKSNyW5Z3f/YKtVBQAAG9xKX3j0+0lul+RPkpxbVRdPP5dU1cVbpzwAANiYVlqjfrW/tRQAALhuCOMAADAgQR0AAAYkqAMAwIAEdQAAGJCgDgAAAxLUAQBgQII6AAAMSFAHAIABCeoAADAgQR0AAAYkqAMAwIAEdQAAGJCgDgAAAxLUAQBgQII6AAAMSFAHAIABCeoAADAgQR0AAAYkqAMAwIAEdQAAGJCgDgAAAxLUAQBgQII6AAAMSFAHAIABCeoAADAgQR0AAAYkqAMAwIAEdQAAGJCgDgAAAxLUAQBgQII6AAAMSFAHAIABCeoAADAgQR0AAAYkqAMAwIAEdQAAGJCgDgAAAxLUAQBgQII6AAAMSFAHAIABCeoAADAgQR0AAAYkqAMAwIAEdQAAGJCgDgAAAxLUAQBgQII6AAAMSFAHAIABCeoAADAgQR0AAAYkqAMAwIAEdQAAGJCgDgAAAxLUAQBgQII6AAAMSFAHAIABCeoAADAgQR0AAAYkqAMAwIAEdQAAGJCgDgAAAxLUAQBgQNuvdQFsPJsO+dBal7DVnXXYY9e6BABgnTGjDgAAAxLUAQBgQII6AAAMSFAHAIABCeoAADAgQR0AAAYkqAMAwIAEdQAAGJCgDgAAAxLUAQBgQII6AAAMSFAHAIABzS2oV9Vbq+r8qvrigrZbVdVxVXXG9HjLqb2q6nVVdWZVfb6q7rvgnIOm/mdU1UEL2u9XVV+YznldVdVKYwAAwHoyzxn1tyXZb1HbIUk+2t17JPnotJ8kj06yx/Tz7CRvTGahO8lLkzwwyQOSvHRB8H7j1HfzefttYQwAAFg35hbUu/vEJBcuat4/yeHT9uFJnrig/e0986kkO1bVLkkeleS47r6wu7+X5Lgk+03Hbt7dn+zuTvL2RddaagwAAFg3tvYa9dt293lJMj3eZmrfNcnZC/qdM7Wt1H7OEu0rjQEAAOvGKB8mrSXa+hq0X71Bq55dVadW1akXXHDB1T0dAADmZmsH9W9Py1YyPZ4/tZ+T5PYL+u2W5NwttO+2RPtKY1xFd7+pu/fq7r123nnna/ykAADgura1g/rRSTbfueWgJO9f0P6M6e4veyf5/rRs5dgkj6yqW04fIn1kkmOnY5dU1d7T3V6esehaS40BAADrxvbzunBVvTvJPkl2qqpzMrt7y2FJjqyqg5N8M8lTpu7HJHlMkjOT/DDJM5Okuy+sqkOTnDL1+4vu3vwB1d/O7M4yN0ry4eknK4wBAADrxtyCencfsMyhRyzRt5M8Z5nrvDXJW5doPzXJPZZo/+5SYwAAwHoyyodJAQCABQR1AAAYkKAOAAADEtQBAGBAgjoAAAxIUAcAgAEJ6gAAMCBBHQAABiSoAwDAgAR1AAAYkKAOAAADEtQBAGBAgjoAAAxIUAcAgAEJ6gAAMCBBHQAABiSoAwDAgAR1AAAYkKAOAAADEtQBAGBAgjoAAAxIUAcAgAEJ6gAAMCBBHQAABiSoAwDAgAR1AAAYkKAOAAADEtQBAGBAgjoAAAxIUAcAgAEJ6gAAMCBBHQAABiSoAwDAgAR1AAAYkKAOAAADEtQBAGBAgjoAAAxIUAcAgAEJ6gAAMCBBHQAABiSoAwDAgAR1AAAYkKAOAAADEtQBAGBAgjoAAAxIUAcAgAEJ6gAAMCBBHQAABiSoAwDAgAR1AAAYkKAOAAADEtQBAGBAgjoAAAxIUAcAgAEJ6gAAMCBBHQAABiSoAwDAgAR1AAAY0PZrXQBsBJsO+dBal7DVnXXYY9e6BABY18yoAwDAgAR1AAAYkKAOAAADEtQBAGBAgjoAAAxIUAcAgAEJ6gAAMCBBHQAABiSoAwDAgAR1AAAYkKAOAAADEtQBAGBAgjoAAAxIUAcAgAEJ6gAAMCBBHQAABiSoAwDAgAR1AAAYkKAOAAADEtQBAGBA2691AcC2adMhH1rrEra6sw577FqXAMA2xIw6AAAMSFAHAIABCeoAADAgQR0AAAYkqAMAwIAEdQAAGNA2e3vGqtovyWuTbJfkzd192BqXBGzj3JISgOvSNjmjXlXbJXl9kkcn2TPJAVW159pWBQAAq7dNBvUkD0hyZnd/rbt/kuSIJPuvcU0AALBq2+rSl12TnL1g/5wkD1yjWgC2WRttuY+lPsDWtK0G9Vqira/SqerZSZ497f6gqr4y16rGsFOS76x1Eaxrfoe4Ntb170+9fK0r2PDW9e8Pa26U3587rrbjthrUz0ly+wX7uyU5d3Gn7n5TkjdtraJGUFWndvdea10H65ffIa4Nvz9cG35/uDbW4+/PtrpG/ZQke1TV7lW1Q5KnJjl6jWsCAIBV2yZn1Lv78qp6bpJjM7s941u7+/Q1LgsAAFZtmwzqSdLdxyQ5Zq3rGNCGWurDXPgd4trw+8O14feHa2Pd/f5U91U+YwkAAKyxbXWNOgAArGuC+gZRVbevqo9X1ZdVc0CyAAAHB0lEQVSr6vSqesFa18T6U1XbVdVpVfXBta6F9aWqdqyqo6rq36b/Dz1orWti/aiqF07/dn2xqt5dVTdc65oYW1W9tarOr6ovLmi7VVUdV1VnTI+3XMsaV0NQ3zguT/L73X23JHsneU5V7bnGNbH+vCDJl9e6CNal1yb5p+7+xST3it8jVqmqdk3y/CR7dfc9MrtJxFPXtirWgbcl2W9R2yFJPtrdeyT56LQ/NEF9g+ju87r7M9P2JZn9I7nr2lbFelJVuyV5bJI3r3UtrC9VdfMkD03yliTp7p9090VrWxXrzPZJblRV2ye5cZb4bhRYqLtPTHLhoub9kxw+bR+e5IlbtahrQFDfgKpqU5L7JDlpbSthnXlNkj9KcuVaF8K68wtJLkjy99PSqTdX1U3WuijWh+7+9ySvTPLNJOcl+X53f2Rtq2Kdum13n5fMJjCT3GaN69kiQX2DqaqbJnlvkt/t7ovXuh7Wh6p6XJLzu/vTa10L69L2Se6b5I3dfZ8kl2Yd/MmZMUzriPdPsnuS2yW5SVU9bW2rgq1DUN9Aqur6mYX0d3b3P651PawrD07yhKo6K8kRSfatqnesbUmsI+ckOae7N/8V76jMgjusxq8k+Xp3X9DdP03yj0l+aY1rYn36dlXtkiTT4/lrXM8WCeobRFVVZutDv9zdr17relhfuvvF3b1bd2/K7ENcH+tuM1qsSnd/K8nZVXXXqekRSb60hiWxvnwzyd5VdePp37JHxIeRuWaOTnLQtH1QkvevYS2rss1+MylX8eAkT0/yhar67NT2kukbXAHm7XlJ3llVOyT5WpJnrnE9rBPdfVJVHZXkM5ndwey0rMNvmGTrqqp3J9knyU5VdU6SlyY5LMmRVXVwZm8An7J2Fa6ObyYFAIABWfoCAAADEtQBAGBAgjoAAAxIUAcAgAEJ6gAAMCBBHWANVVVX1asW7P9BVf3ZdXTtt1XVk6+La21hnKdU1Zer6uOL2jdV1Y+q6rNV9aWqevv0xWvXZIy9qup1103FAOuDoA6wti5L8qSq2mmtC1moqra7Gt0PTvI73f3wJY59tbvvneSeSXZL8l+vST3dfWp3P/+anAuwXgnqAGvr8sy+vOWFiw8snhGvqh9Mj/tU1QlVdWRV/d+qOqyqDqyqk6vqC1V1pwWX+ZWq+pep3+Om87erqldU1SlV9fmq+q0F1/14Vb0ryReWqOeA6fpfrKqXT21/muQhSf5XVb1iuSfZ3VckOTnJrluo4T1V9ZhFr8GvTbV9cGq7SVW9dTr3tKraf2o/pqr+87R92lRbqurQqvrNqtqlqk6cZvi/WFW/vKX/OABrSVAHWHuvT3JgVd3iapxzryQvyGym+ulJ7tLdD0jy5sy+BXSzTUkeluSxmYXpG2Y2A/797r5/kvsneVZV7T71f0CSP+7uPRcOVlW3S/LyJPsmuXeS+1fVE7v7L5KcmuTA7v7D5Yqdxn1gkn+ampar4Ygk/890zg6ZfV384m9Q/uMkH5vOfXiSV1TVTZKcmOSXq+rmmb0BevDU/yFJ/iXJryc5dprhv1eSzwZgYII6wBrr7ouTvD3J1VnacUp3n9fdlyX5apKPTO1fyCycb3Zkd1/Z3Wck+VqSX0zyyCTPqKrPJjkpya2T7DH1P7m7v77EePdPcnx3X9Ddlyd5Z5KHrqLOO03jfDfJN7v781P7cjV8OMm+VXWDJI9OcmJ3/2jRNR+Z5JDp3OOT3DDJHTIL4w/NLJh/KMlNq+rGSTZ191eSnJLkmdNnAO7Z3Zeson6ANbP9WhcAQJLkNUk+k+TvF7RdnmlCpaoqyQ4Ljl22YPvKBftX5uf/396LxukkleR53X3swgNVtU+SS5epr7b4DJb21e6+d1XtkuT4qnpCdx+9XA1THccneVRmM+vvXqaWX5vC98LzdkiyV2ZvSI5LslOSZyX5dJJ094lV9dDM/rrwD1X1iu5++zV8XgBzZ0YdYADdfWGSIzNbErLZWUnuN23vn+Sa3DHlKVV1vWnd+i8k+UqSY5P89uY7sFTVXaalIys5KcnDqmqn6YOmByQ5YbVFdPd5SQ5J8uKpaaUajkjyzCS/PPVb7Ngkz5vevKSq7jON8ZMkZ2f2gdVPZTbD/gfTY6rqjknO7+6/S/KWJPddbf0Aa0FQBxjHqzKbBd7s7zILxydntr57udnulXwls0D94ST/vbt/nNk69i8l+UxVfTHJ32YLf2GdgvaLk3w8yeeSfKa73381a3lfkhtPH+JcqYaPZLaE5Z+n8L3YoZm9afn8dO6hC479S5Jvd/cPp+3dpsck2SfJZ6vqtCS/luS1V7N+gK2quhf/VRQAAFhrZtQBAGBAgjoAAAxIUAcAgAEJ6gAAMCBBHQAABiSoAwDAgAR1AAAYkKAOAAAD+v8BHmXHCvU5E/YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# count of reviews by users\n",
    "ratings_num_df['count'] = 1\n",
    "user_counts = ratings_num_df.groupby('reviewerID').agg({'count':np.sum}).reset_index()\n",
    "user_counts['count'] = np.log(user_counts['count'])\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.hist(user_counts['count'])\n",
    "plt.xlabel('Number of Reviews (log)')\n",
    "plt.ylabel('Number of Users')\n",
    "plt.title('Histogram of reviews by user')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.739958056415116\n",
      "8.0\n",
      "0    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#user_counts = ratings_num_df.groupby('reviewerID').agg({'count':np.sum}).reset_index()\n",
    "print(user_counts['count'].mean())\n",
    "print(user_counts['count'].median())\n",
    "print(user_counts['count'].mode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training vs Test data\n",
    "\n",
    "In order to get an idea of the performance of each method, I split the data into training and test sets. I use the same random seed in order to make sure each algorithm gets the same training and test data.\n",
    "\n",
    "## Baseline\n",
    "\n",
    "Before exploring each algorithm, we need a baseline of comparison. A simple baseline model would be to take the mean. But which mean? We could take the overall mean of all items, and predict this single value for everything. We could also take the mean of each individual item, and guess this when the item appears in the test data, or we could do the same but by users. An important note in these last two techniques is there is a chance some users or items will appear in the test data, but not the training data. In this case the overall mean will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "train_df, test_df = train_test_split(ratings_num_df, test_size = .1, random_state = 42)\n",
    "\n",
    "# get overall mean in training data\n",
    "overall_mean = train_df['rating'].mean()\n",
    "\n",
    "# get item based means in training data\n",
    "item_means = train_df.groupby('asin').agg({'rating': np.mean}).reset_index()\n",
    "item_means.columns = ['asin', 'item_mean']\n",
    "\n",
    "# get user based means in training data\n",
    "user_means = train_df.groupby('reviewerID').agg({'rating': np.mean}).reset_index()\n",
    "user_means.columns = ['reviewerID', 'user_mean']\n",
    "\n",
    "test_means_df = test_df.copy()\n",
    "test_means_df['overall_mean'] = overall_mean\n",
    "test_means_df = test_means_df.merge(item_means, on = 'asin', how = 'left')\n",
    "test_means_df = test_means_df.merge(user_means, on = 'reviewerID', how = 'left')\n",
    "test_means_df = test_means_df.fillna(overall_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall mean RMSE: 1.0578301022101093\n",
      "Item mean RMSE: 1.0100346145012609\n",
      "User mean RMSE: 0.9659171214770267\n"
     ]
    }
   ],
   "source": [
    "# user RMSE to see performance of each\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "print(\"Overall mean RMSE: {}\".format(np.sqrt(mse(test_means_df['rating'], test_means_df['overall_mean']))))\n",
    "print(\"Item mean RMSE: {}\".format(np.sqrt(mse(test_means_df['rating'], test_means_df['item_mean']))))\n",
    "print(\"User mean RMSE: {}\".format(np.sqrt(mse(test_means_df['rating'], test_means_df['user_mean']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using item or user mean does slightly better than guessing the overall mean, but not by a huge amount. So the goal is to find a method that can do significantly better than about .96 RMSE.\n",
    "\n",
    "## Linear Regression\n",
    "\n",
    "I'll start with a relatively simple method of using linear regression. The idea is that the user and item means are likely correlated, so taking both into account will generate some improvement in prediction. So in the training data I'll regress the ratings on user and item mean, and use this model to generate predictions in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben/anaconda2/envs/tensorflow/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>rating</td>      <th>  R-squared:         </th>  <td>   0.961</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.961</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>9.996e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 05 Apr 2018</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:06:48</td>     <th>  Log-Likelihood:    </th> <td>-1.0151e+07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>8008236</td>     <th>  AIC:               </th>  <td>2.030e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>8008234</td>     <th>  BIC:               </th>  <td>2.030e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>item_mean</th> <td>    0.3224</td> <td>    0.000</td> <td>  670.336</td> <td> 0.000</td> <td>    0.321</td> <td>    0.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_mean</th> <td>    0.6824</td> <td>    0.000</td> <td> 1424.725</td> <td> 0.000</td> <td>    0.681</td> <td>    0.683</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1630131.567</td> <th>  Durbin-Watson:     </th>  <td>   1.998</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>    <th>  Jarque-Bera (JB):  </th> <td>3166161.695</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td>-1.245</td>    <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td> 4.814</td>    <th>  Cond. No.          </th>  <td>    13.5</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 rating   R-squared:                       0.961\n",
       "Model:                            OLS   Adj. R-squared:                  0.961\n",
       "Method:                 Least Squares   F-statistic:                 9.996e+07\n",
       "Date:                Thu, 05 Apr 2018   Prob (F-statistic):               0.00\n",
       "Time:                        20:06:48   Log-Likelihood:            -1.0151e+07\n",
       "No. Observations:             8008236   AIC:                         2.030e+07\n",
       "Df Residuals:                 8008234   BIC:                         2.030e+07\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "item_mean      0.3224      0.000    670.336      0.000       0.321       0.323\n",
       "user_mean      0.6824      0.000   1424.725      0.000       0.681       0.683\n",
       "==============================================================================\n",
       "Omnibus:                  1630131.567   Durbin-Watson:                   1.998\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          3166161.695\n",
       "Skew:                          -1.245   Prob(JB):                         0.00\n",
       "Kurtosis:                       4.814   Cond. No.                         13.5\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import statsmodel\n",
    "import statsmodels.api as sm\n",
    "# create new training dataframe with user and item means\n",
    "train_ols_df = train_df.copy()\n",
    "train_ols_df = train_ols_df.merge(item_means, on = 'asin', how = 'left')\n",
    "train_ols_df = train_ols_df.merge(user_means, on = 'reviewerID', how = 'left')\n",
    "train_ols_df = train_ols_df[['rating', 'item_mean', 'user_mean']]\n",
    "\n",
    "# build ols model\n",
    "ols_model = sm.OLS(train_ols_df['rating'], train_ols_df[['item_mean', 'user_mean']]).fit()\n",
    "ols_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS RMSE: 0.9272107100780972\n"
     ]
    }
   ],
   "source": [
    "# now predict on the test data\n",
    "\n",
    "test_ols_df = test_df.copy()\n",
    "test_ols_df = test_ols_df.merge(item_means, on = 'asin', how = 'left')\n",
    "test_ols_df = test_ols_df.merge(user_means, on = 'reviewerID', how = 'left')\n",
    "test_ols_df = test_ols_df.fillna(overall_mean)\n",
    "test_ols_df['prediction'] = ols_model.predict(test_ols_df[['item_mean', 'user_mean']])\n",
    "test_ols_df['prediction'] = [5 if i>5 else 1 if i<1 else i for i in test_ols_df['prediction']]\n",
    "\n",
    "print(\"OLS RMSE: {}\".format(np.sqrt(mse(test_ols_df['rating'], test_ols_df['prediction']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's an improvement beyond the baseline. So it appears there is some correlation in item and user mean that OLS accounts for. To go a step futher, I add an interaction to the OLS model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>rating</td>      <th>  R-squared:         </th>  <td>   0.964</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.964</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>7.067e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 05 Apr 2018</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:06:52</td>     <th>  Log-Likelihood:    </th> <td>-9.9245e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>8008236</td>     <th>  AIC:               </th>  <td>1.985e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>8008233</td>     <th>  BIC:               </th>  <td>1.985e+07</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>item_mean</th>     <td>    0.1454</td> <td>    0.001</td> <td>  272.040</td> <td> 0.000</td> <td>    0.144</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>user_mean</th>     <td>    0.3196</td> <td>    0.001</td> <td>  452.158</td> <td> 0.000</td> <td>    0.318</td> <td>    0.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>item_user_int</th> <td>    0.1255</td> <td>    0.000</td> <td>  682.075</td> <td> 0.000</td> <td>    0.125</td> <td>    0.126</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1043573.771</td> <th>  Durbin-Watson:     </th>  <td>   1.999</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>    <th>  Jarque-Bera (JB):  </th> <td>1855918.572</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td>-0.865</td>    <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td> 4.603</td>    <th>  Cond. No.          </th>  <td>    48.2</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 rating   R-squared:                       0.964\n",
       "Model:                            OLS   Adj. R-squared:                  0.964\n",
       "Method:                 Least Squares   F-statistic:                 7.067e+07\n",
       "Date:                Thu, 05 Apr 2018   Prob (F-statistic):               0.00\n",
       "Time:                        20:06:52   Log-Likelihood:            -9.9245e+06\n",
       "No. Observations:             8008236   AIC:                         1.985e+07\n",
       "Df Residuals:                 8008233   BIC:                         1.985e+07\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "item_mean         0.1454      0.001    272.040      0.000       0.144       0.146\n",
       "user_mean         0.3196      0.001    452.158      0.000       0.318       0.321\n",
       "item_user_int     0.1255      0.000    682.075      0.000       0.125       0.126\n",
       "==============================================================================\n",
       "Omnibus:                  1043573.771   Durbin-Watson:                   1.999\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1855918.572\n",
       "Skew:                          -0.865   Prob(JB):                         0.00\n",
       "Kurtosis:                       4.603   Cond. No.                         48.2\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ols_df['item_user_int'] = train_ols_df['item_mean'] * train_ols_df['user_mean'] \n",
    "\n",
    "# build ols model\n",
    "ols_model = sm.OLS(train_ols_df['rating'], train_ols_df[['item_mean', 'user_mean', \n",
    "                                                         'item_user_int']]).fit()\n",
    "ols_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS with interaction RMSE: 0.9234251459852182\n"
     ]
    }
   ],
   "source": [
    "test_ols_df['item_user_int'] = test_ols_df['item_mean'] * test_ols_df['user_mean'] \n",
    "test_ols_df['prediction'] = ols_model.predict(test_ols_df[['item_mean', 'user_mean', 'item_user_int']])\n",
    "test_ols_df['prediction'] = [5 if i>5 else 1 if i<1 else i for i in test_ols_df['prediction']]\n",
    "\n",
    "print(\"OLS with interaction RMSE: {}\".format(np.sqrt(mse(test_ols_df['rating'], test_ols_df['prediction']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that does only slightly better. Adding terms to a regression model will always improve its performance on the training data, but in this case we see improvement on the test data, indicating that the interactions might actually be identifying something. For example, this could mean that users that already give high ratings are more likely to give high ratings when they're reviewing an item that tends to get a high rating.\n",
    "\n",
    "## Cosine Similarity\n",
    "\n",
    "Next I try cosine similarity between users. Cosine similarity between two users (k and a) is calculated as\n",
    "\n",
    "## $S_{u}^{cos}(u_{k},u_{a}) = \\frac{u_{k} \\cdot u_{a}}{||u_{k}|| ||u_{a}||} = \\frac{\\Sigma x_{k,m}x_{a,m}}{\\sqrt{\\Sigma x_{k,m}^{2}x_{a,m}^{2}}}$\n",
    "\n",
    "Where m is an item. In qualitative terms, this means find two users that have reviewed the same items. For each user, construct a vector of the items both have reviewed, and calculate the angle between those vectors. This gives us some idea of which users have similar tastes. We can then plug these similarities in as an adjustment to the user mean using the formula\n",
    "\n",
    "## $\\hat{x}_{k,m} = \\bar{x}_{k} + \\frac{\\Sigma_{u_{a}} sim_{u}(u_{k},u_{a})(x_{a,m} - \\bar{x}_{u_{a}})}{\\Sigma_{u_{a}}|sim_{u}(u_{k},u_{a})|}$\n",
    "\n",
    "Again, in qualitative terms, if we want to estimate the rating for a given user, take that user's mean. Then for each follow user for which we have a similarity and that follow user has reviewed the item of interest, get the difference in the fellow user's rating for that item and the fellow user's overall mean. Multiply by the user similarity. Sum across all users for which these criteria are met, and divide by the magnitude of all similarities in this set of users.\n",
    "\n",
    "### Computational Difficulty\n",
    "\n",
    "Cosine similarity presents a particular challenge with this dataset because of its size. There are 603668 users in the data, which means calculating 364,415,054,224 similarity scores. Assuming the values are stored as standard double precision floating point values, this is about 3TB of data, far more than can fit in memory on most machines (the machine I'm using for the analysis has 32GB of RAM). However, the vast majority of these values will be zero, and the vast majority of calculations only need to be performed between a limited number of users. Therefore, the data can be represented in a sparse matrix form of a more reasonable size.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start by generating a sparse matrix of the training data\n",
    "from scipy import sparse\n",
    "\n",
    "arr = np.array(train_df)\n",
    "shape = tuple([arr.max(axis=0)[2]+1] + [arr.max(axis=0)[0]+1])\n",
    "train_adj = sparse.csc_matrix((arr[:,1], (arr[:,2], arr[:,0])), shape = shape, dtype = arr.dtype)\n",
    "\n",
    "# need to user means for the second part of the calcuation\n",
    "user_means = train_df.groupby('reviewerID').agg({'rating':np.mean}).reset_index()\n",
    "user_means.columns = ['reviewerID', 'user_mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scipy cosine_similarity function will calculate the cosine similarity for a sparse matrix. It can be set to return a sparse matrix, but will attempt to calculate all values for the matrix first, which means it will take far too long to apply to the entire user matrix. Instead, I use the function below to take user item pairs that appears in the test data, and calculates only the similarities needed for those ratings. The results are written to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a given user item pair, get all users that reviewed that item\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def compute_sim_df(user, item):\n",
    "    users = train_adj.getcol(item).indices\n",
    "    users_reviews = train_adj[users]\n",
    "    target = train_adj[user]\n",
    "    all_sims = cosine_similarity(target, users_reviews)[0]\n",
    "    sims = all_sims[np.nonzero(all_sims)]\n",
    "    users = users[np.nonzero(all_sims)]\n",
    "    sims = pd.DataFrame({'peer':users, 'similarity':sims})\n",
    "    sims['asin'] = item\n",
    "    sims['user'] = user\n",
    "    sims = sims.fillna(overall_mean)\n",
    "    return sims\n",
    "\n",
    "def compute_many_sim_df(users, items):\n",
    "    dfs = [compute_sim_df(i,j) for i,j in zip(users, items)]\n",
    "    return pd.concat(dfs, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use multiprocessing and write each to a file\n",
    "import os\n",
    "os.makedirs('cosine_sims')\n",
    "def sims_to_file(users_items_filename_tuple):\n",
    "    users = users_items_filename_tuple[0]\n",
    "    items = users_items_filename_tuple[1]\n",
    "    filename = users_items_filename_tuple[2]\n",
    "    df = compute_many_sim_df(users, items)\n",
    "    df.to_csv('cosine_sims/sims_{}.csv'.format(filename), index = False)\n",
    "    print('sims_{}'.format(filename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things easier, break in into segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 1000\n",
    "user_inputs = [list(test_df['reviewerID'][i*block_size:i*block_size+block_size]) for i in range(test_df.shape[0]//block_size + 1)]\n",
    "item_inputs = [list(test_df['asin'][i*block_size:i*block_size+block_size]) for i in range(test_df.shape[0]//block_size + 1)]\n",
    "indices = [i for i in range(test_df.shape[0]//block_size + 1)]\n",
    "\n",
    "inputs = [(i,j,k) for i,j,k in zip(user_inputs, item_inputs, indices)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output files with similarity measures for users and items in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this takes about 4-5 hours\n",
    "\n",
    "from time import time\n",
    "import multiprocessing\n",
    "pool = multiprocessing.Pool(processes = 8)\n",
    "start = time()\n",
    "pool.map(sims_to_file, inputs)\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, load the files back in and produce a dataframe of user means, similarities to other users (peers) and the means of those peers on the items we wish to rate. Then, use the similarity score in the formula above to adjust the user mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity RMSE: 0.9350693421681338\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "files = os.listdir('cosine_sims')\n",
    "\n",
    "# read similarity files for all user items pairs in the test set\n",
    "sims = []\n",
    "for file in files:\n",
    "    sims.append(pd.read_csv('cosine_sims/{}'.format(file)))\n",
    "    \n",
    "sims = pd.concat(sims, axis = 0).reset_index(drop = True)\n",
    "\n",
    "# merge with user means\n",
    "sims = sims.merge(user_means, left_on = 'user', right_on = 'reviewerID', how = 'left')\n",
    "\n",
    "sims = sims.drop('reviewerID', axis = 1)\n",
    "sims.columns = ['peer', 'similarity', 'asin', 'user', 'user_mean']\n",
    "\n",
    "# merge with means for peers\n",
    "sims = sims.merge(user_means, left_on = 'peer', right_on = 'reviewerID', how = 'left')\n",
    "\n",
    "sims = sims.drop('reviewerID', axis = 1)\n",
    "sims.columns = ['peer', 'similarity', 'asin', 'user', 'user_mean', 'peer_mean']\n",
    "\n",
    "# get the ratings of peers in the training set\n",
    "sims = sims.merge(train_df, left_on = ['peer', 'asin'], right_on = ['reviewerID', 'asin'], how = 'left')\n",
    "\n",
    "sims = sims.drop('reviewerID', axis = 1)\n",
    "sims.columns = ['peer', 'similarity', 'asin', 'user', 'user_mean', 'peer_mean', 'peer_rating']\n",
    "\n",
    "# calculate new scores\n",
    "sims['peer_dif'] = sims['peer_rating'] - sims['peer_mean']\n",
    "sims['peer_adjustment'] = sims['peer_dif'] * sims['similarity']\n",
    "sims['similarity_magnitude'] = np.abs(sims['similarity'])\n",
    "sims_group = sims.groupby(['user', 'asin']).agg({'user_mean': np.mean, 'peer_adjustment': np.sum,\n",
    "                                                 'similarity_magnitude': np.sum}).reset_index()\n",
    "sims_group['adjustment'] = sims_group['peer_adjustment']/sims_group['similarity_magnitude']\n",
    "sims_group['prediction'] = sims_group['user_mean'] + sims_group['adjustment']\n",
    "sims_group['prediction'] = [5 if i>5 else 1 if i<1 else i for i in sims_group['prediction']]\n",
    "\n",
    "predictions = sims_group[['user', 'asin', 'prediction']]\n",
    "predictions.columns = ['reviewerID', 'asin', 'prediction']\n",
    "\n",
    "# get real scores from test set\n",
    "test_predictions = test_df.merge(predictions, on = ['reviewerID', 'asin'], how = 'inner')\n",
    "\n",
    "print(\"Cosine Similarity RMSE: {}\".format(np.sqrt(mse(test_predictions['rating'],\n",
    "                                                                     test_predictions['prediction']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite all that work to generate the similarity scores for collaborative filtering, the end result did a bit worse than linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition\n",
    "\n",
    "The more common form of collaborative filtering in current recommendation systems is singular value decomposition (SVD). SVD works similar to PCA. Starting with an MxN matrix, we can describe an approximation of the matrix with three matrices of size MxD, DxD, and DxN, where D is some set of latent factors. For example, if we generate an SVD with 20 latent factors, we are essentially allowing the algorithm to find 20 underlying variables that describe the ratings in the dataset. The latent values can then be multiplied together to get new predictions.\n",
    "\n",
    "Performing SVD on a matrix of 600,000x300,000 would be computationally intractable. Fortunately, SciPy includes a singular value decomposition function for sparse matrices. With this, we can produce the three matrices in a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create svd matrices, takes about 5 minutes\n",
    "\n",
    "u, s, vt = svds(train_adj, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions for the test data\n",
    "s_diag_matrix=np.diag(s)\n",
    "X_pred = [np.dot(np.dot(u[i], s_diag_matrix), vt[:,j]) for i,j in zip(test_df['reviewerID'], test_df['asin'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6951466841137655"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pred = np.array(X_pred)\n",
    "user_means = test_df[['reviewerID', 'rating']].groupby('reviewerID').mean().reset_index()\n",
    "user_means.columns = ['reviewerID', 'user_mean_overall']\n",
    "\n",
    "test_ratings_result = test_df.merge(user_means, on = 'reviewerID', how = 'inner')\n",
    "test_ratings_result['X_pred'] = X_pred\n",
    "test_ratings_result['X_pred'] = test_ratings_result['X_pred'] + test_ratings_result['user_mean_overall']\n",
    "test_ratings_result['X_pred'] = [5 if i>5 else 1 if i<1 else i for i in test_ratings_result['X_pred']]\n",
    "\n",
    "svd_rmse = np.sqrt(mse(test_ratings_result['rating'], test_ratings_result['X_pred']))\n",
    "svd_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a huge improvement! So far, it looks like SVD is performing the best by a significant margin.\n",
    "\n",
    "## Neural Networks\n",
    "\n",
    "Neural networks have proved to be very effective at generating recommendations. The winning entry in the Netflix prize employed an ensemble of methods, including a neural network based on Geoffrey Hinton's concept of a restricted Boltzmann machine for collaborative filtering (the original paper can be found [here](https://www.cs.toronto.edu/~rsalakhu/papers/rbmcf.pdf). Below, I build a similar Boltzmann machine in Tensorflow. Building an RBM such that it could handle a sparse matrix input proved to be more difficult than expected, and the structure could likely use some further refining in order to optimize the results, but it does demonstrate the basic concept.\n",
    "\n",
    "### Restricted Boltzmann Machine\n",
    "\n",
    "A restricted Boltzmann machine (RBM) uses a two layer neural network, a visible and a hiding layer, where the hidden layer is trained to reconstruct the the visible layer. Nodes in the hidden layer are activated as a probability function based on the visible layer, and weights on the ties. For example, if an input node is active, and the weight on a given tie is .8, the associated hidden node has a probability of sigmoid(.8) of being activated. The hidden nodes are then fed back to the weights to reconstruct the input. In this case, a mask is then applied so only non-zero values are used in calculating the loss function. This is because we don't want the RBM to reconstruct 0 values, as these are the values we are trying to predict.\n",
    "\n",
    "Training is done using contrasted divergence, which calculates the difference between the input and the predicted reconstruction from the hidden nodes. Again, for training all 0 values on the input are masked to zero, so are not considered in the contrasted divergence. Predictions are then made by feeding in a user's row from the training data, and the results are generated without the mask, and the prediction for new items are taken from the reconstructed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in Tensorflow and other required packages\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_num_df['rating'] = ratings_num_df['rating']/5\n",
    "\n",
    "train_df, test_df = train_test_split(ratings_num_df, test_size = .1, random_state = 42)\n",
    "\n",
    "# start by generating a sparse matrix of the training data\n",
    "from scipy import sparse\n",
    "\n",
    "arr = np.array(train_df)\n",
    "shape = tuple([arr.max(axis=0)[2]+1] + [arr.max(axis=0)[0]+1])\n",
    "train_adj = sparse.csc_matrix((arr[:,1], (arr[:,2], arr[:,0])), shape = shape, dtype = arr.dtype)\n",
    "\n",
    "arr = np.array(test_df)\n",
    "shape = tuple([arr.max(axis=0)[2]+1] + [arr.max(axis=0)[0]+1])\n",
    "test_adj = sparse.csc_matrix((arr[:,1], (arr[:,2], arr[:,0])), shape = shape, dtype = arr.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set visible and hidden size\n",
    "tf.reset_default_graph()\n",
    "\n",
    "hiddenUnits = 64\n",
    "visibleUnits = len(set(ratings_num_df['asin']))\n",
    "vb = tf.placeholder(\"float\", [visibleUnits]) #Number of unique movies\n",
    "hb = tf.placeholder(\"float\", [hiddenUnits]) #Number of features we're going to learn\n",
    "W = tf.placeholder(\"float\", [visibleUnits, hiddenUnits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phase 1: Input Processing\n",
    "v0 = tf.placeholder(\"float\", [None, visibleUnits])\n",
    "mask = tf.sign(v0)\n",
    "_h0= tf.nn.sigmoid(tf.matmul(v0, W) + hb)\n",
    "h0 = tf.nn.relu(tf.sign(_h0 - tf.random_uniform(tf.shape(_h0))))\n",
    "#Phase 2: Reconstruction\n",
    "_v1 = tf.nn.sigmoid(tf.matmul(h0, tf.transpose(W)) + vb) \n",
    "v1t = tf.nn.relu(tf.sign(_v1 - tf.random_uniform(tf.shape(_v1))))\n",
    "v1 = tf.multiply(v1t, mask)\n",
    "h1 = tf.nn.sigmoid(tf.matmul(v1, W) + hb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning rate\n",
    "alpha = 1\n",
    "#Create the gradients\n",
    "w_pos_grad = tf.matmul(tf.transpose(v0), h0)\n",
    "w_neg_grad = tf.matmul(tf.transpose(v1), h1)\n",
    "#Calculate the Contrastive Divergence to maximize\n",
    "CD = (w_pos_grad - w_neg_grad) / tf.to_float(tf.shape(v0)[0])\n",
    "#Create methods to update the weights and biases\n",
    "update_w = W + alpha * CD\n",
    "update_vb = vb + alpha * tf.reduce_mean(v0 - v1, 0)\n",
    "update_hb = hb + alpha * tf.reduce_mean(h0 - h1, 0)\n",
    "err = v0 - v1\n",
    "err_sum = tf.divide(tf.reduce_sum(tf.square(err)), tf.count_nonzero(v0, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Current weight\n",
    "cur_w = np.zeros([visibleUnits, hiddenUnits], np.float32)\n",
    "#Current visible unit biases\n",
    "cur_vb = np.zeros([visibleUnits], np.float32)\n",
    "#Current hidden unit biases\n",
    "cur_hb = np.zeros([hiddenUnits], np.float32)\n",
    "#Previous weight\n",
    "prv_w = np.zeros([visibleUnits, hiddenUnits], np.float32)\n",
    "#Previous visible unit biases\n",
    "prv_vb = np.zeros([visibleUnits], np.float32)\n",
    "#Previous hidden unit biases\n",
    "prv_hb = np.zeros([hiddenUnits], np.float32)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb2e106c17f41bfa6b573fdbe6d3a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 :: Error=0.36415\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ben/anaconda2/envs/tensorflow/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ben/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/ben/anaconda2/envs/tensorflow/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 :: Error=0.33124\n",
      "Step 200 :: Error=0.31626\n",
      "Step 300 :: Error=0.32523\n",
      "Step 400 :: Error=0.30051\n",
      "Step 500 :: Error=0.30621\n",
      "Step 600 :: Error=0.29396\n",
      "Step 700 :: Error=0.26286\n",
      "Step 800 :: Error=0.25796\n",
      "Step 900 :: Error=0.25354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "errors = []\n",
    "for i in tqdm(range(10000)):\n",
    "    start = np.random.randint(0, train_adj.shape[0] - batch_size)\n",
    "    batch = train_adj[start:start + batch_size].todense()\n",
    "    cur_w, cur_vb, cur_nb = sess.run([update_w, update_vb, update_hb], feed_dict={v0: batch, W: prv_w, vb: prv_vb, hb: prv_hb})\n",
    "    prv_w = cur_w\n",
    "    prv_vb = cur_vb\n",
    "    prv_hb = cur_nb\n",
    "    if i%100==0:\n",
    "        err = sess.run(err_sum, feed_dict={v0: batch, W: cur_w, vb: cur_vb, hb: cur_nb})\n",
    "        print('Step {:.0f} :: Error={:.5f}'.format(i, err))\n",
    "        errors.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to generate predicitons\n",
    "\n",
    "def get_test_prediction(user_id_list, item_id_list):\n",
    "    #row = np.array(test_adj[user_id_list].todense()) \n",
    "    #actual = [row[i, item_id_list[i]] * 5 for i in range(row.shape[0])]\n",
    "    inputUser = train_adj[user_id_list].todense()\n",
    "    hh0 = tf.nn.sigmoid(tf.matmul(v0, W) + hb)\n",
    "    vv1 = tf.nn.sigmoid(tf.matmul(hh0, tf.transpose(W)) + vb)\n",
    "    feed = sess.run(hh0, feed_dict={ v0: inputUser, W: prv_w, hb: prv_hb})\n",
    "    rec = sess.run(vv1, feed_dict={ hh0: feed, W: prv_w, vb: prv_vb})\n",
    "    predicted = [rec[i, item_id_list[i]] * 5 for i in range(rec.shape[0])]\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff78aef538d744cd8499e48f668d2111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_rbm = []\n",
    "batch_size = 100\n",
    "#test_df.shape[0]\n",
    "for i in tqdm(range(0, 5000, batch_size)):\n",
    "    predicted = get_test_prediction(list(test_df['reviewerID'][i:i+batch_size]), list(test_df['asin'][i:i+batch_size]))\n",
    "    predictions_rbm.extend(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMB RMSE: 1.128565029561967\n"
     ]
    }
   ],
   "source": [
    "print(\"RMB RMSE: {}\".format(np.sqrt(mse(test_df['rating'] * 5, predictions_rbm))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the RBM is learning something, but it's performing far behind the SVD, and worse than the baseline. This is something that would likely take a lot more work. While the SVD calculations are pretty straightforward, the neural networks will generally be more flexible, can take all different kinds of hyperparameters, structural modifications, regularization, and fitting strategies. So, while it might be possible to fit a neural network that can outperform SVD, it would likely take a lot of time and research. However, we can say this network is learning something, based on the change in the loss function, so there is potential worth investigating.\n",
    "\n",
    "This actually reminds me of a joke I heard recently, \"It took our team of 18 researchers 4 months to build a neural network that outperforms logistic regression on our data.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder \n",
    "\n",
    "Finally, I try an autoencoder neural network. Similar to an RBM, an autoencoder attempts to reconstruct a set of input values, but instead of using a two layer network that attempts to reconstruct an input, an autoencoder looks more like a feed forward neural network, but in this case, the target is just a set of nodes the same size as the input. The loss function just takes these output nodes and compares them to the input. Like the RBM case, the output is masked so that only non-zero values are considered in calculating the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build tf autoencoder\n",
    "\n",
    "input_dim = 367982\n",
    "n_hidden_1 = 64\n",
    "n_hidden_2 = 64\n",
    "n_hidden_3 = 64\n",
    "n_hidden_4 = 64\n",
    "\n",
    "training_epochs = 10\n",
    "batch_size = 200\n",
    "total_batches = (train_adj.shape[0] // batch_size)\n",
    "\n",
    "learning_rate = 0.00002\n",
    "l2_reg_rate = 0.00001\n",
    "keep_prob = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None,input_dim])\n",
    "zero = tf.constant(0, dtype=tf.float32)\n",
    "where = tf.not_equal(X, zero)\n",
    "X_masked = tf.boolean_mask(X, where)\n",
    "\n",
    "# dropout to deal with denoising\n",
    "X_drop = tf.contrib.layers.dropout(X, keep_prob)\n",
    "\n",
    "e_weights_h1 = tf.get_variable(\"el1\", shape = [input_dim, n_hidden_1], initializer = tf.contrib.layers.xavier_initializer())\n",
    "e_biases_h1 = tf.Variable(tf.constant(0.1, shape = [n_hidden_1]))\n",
    "\n",
    "e_weights_h2 = tf.get_variable(\"el2\", shape = [n_hidden_1, n_hidden_2], initializer = tf.contrib.layers.xavier_initializer())\n",
    "e_biases_h2 = tf.Variable(tf.constant(0.1, shape = [n_hidden_2]))\n",
    "\n",
    "e_weights_h3 = tf.get_variable(\"el3\", shape = [n_hidden_2, n_hidden_3], initializer = tf.contrib.layers.xavier_initializer())\n",
    "e_biases_h3 = tf.Variable(tf.constant(0.1, shape = [n_hidden_3]))\n",
    "\n",
    "e_weights_h4 = tf.get_variable(\"el4\", shape = [n_hidden_3, n_hidden_4], initializer = tf.contrib.layers.xavier_initializer())\n",
    "e_biases_h4 = tf.Variable(tf.constant(0.1, shape = [n_hidden_4]))\n",
    "\n",
    "d_weights_h1 = tf.get_variable(\"dl1\", shape = [n_hidden_4, n_hidden_3], initializer = tf.contrib.layers.xavier_initializer())\n",
    "d_biases_h1 = tf.Variable(tf.constant(0.1, shape = [n_hidden_3]))\n",
    "\n",
    "d_weights_h2 = tf.get_variable(\"dl2\", shape = [n_hidden_3, n_hidden_2], initializer = tf.contrib.layers.xavier_initializer())\n",
    "d_biases_h2 = tf.Variable(tf.constant(0.1, shape = [n_hidden_2]))\n",
    "\n",
    "d_weights_h3 = tf.get_variable(\"dl3\", shape = [n_hidden_2, n_hidden_1], initializer = tf.contrib.layers.xavier_initializer())\n",
    "d_biases_h3 = tf.Variable(tf.constant(0.1, shape = [n_hidden_1]))\n",
    "\n",
    "d_weights_h4 = tf.get_variable(\"dl4\", shape = [n_hidden_1, input_dim], initializer = tf.contrib.layers.xavier_initializer())\n",
    "d_biases_h4 = tf.Variable(tf.constant(0.1, shape = [input_dim]))\n",
    "\n",
    "e1 = tf.nn.softsign(tf.add(tf.matmul(X,e_weights_h1),e_biases_h1))\n",
    "e2 = tf.nn.softsign(tf.add(tf.matmul(e1,e_weights_h2),e_biases_h2))\n",
    "e3 = tf.nn.softsign(tf.add(tf.matmul(e2,e_weights_h3),e_biases_h3))\n",
    "e4 = tf.nn.sigmoid(tf.add(tf.matmul(e3,e_weights_h4),e_biases_h4))\n",
    "\n",
    "d1 = tf.nn.softsign(tf.add(tf.matmul(e4,d_weights_h1),d_biases_h1))\n",
    "d2 = tf.nn.softsign(tf.add(tf.matmul(d1,d_weights_h2),d_biases_h2))\n",
    "d3 = tf.nn.softsign(tf.add(tf.matmul(d2,d_weights_h3),d_biases_h3))\n",
    "d4 = tf.nn.sigmoid(tf.add(tf.matmul(d3,d_weights_h4),d_biases_h4))\n",
    "\n",
    "Y_masked = tf.boolean_mask(d4, where)\n",
    "\n",
    "regularizer = tf.contrib.layers.l2_regularizer(l2_reg_rate)\n",
    "\n",
    "reg_loss = regularizer(e_weights_h1) + regularizer(e_weights_h2) \\\n",
    "+ regularizer(e_weights_h3) + regularizer(e_weights_h4) \n",
    "\n",
    "cost_function = tf.sqrt(tf.reduce_mean(tf.square(X_masked - Y_masked)))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f86aa867d52c40b0a394d2cdec7da856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3018), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32041246\n",
      "0.2987\n",
      "0.28144383\n",
      "0.26411265\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739db1500ee94b4d99aa81dd388c4b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3018), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2739889\n",
      "0.2632184\n",
      "0.25756118\n",
      "0.24504296\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d558bf59643b4bb083c76f3ddf6de66f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3018), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24533494\n",
      "0.23983532\n",
      "0.24140644\n",
      "0.23181376\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84803443aa74b6ead527a861a4b5dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3018), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2249715\n",
      "0.22330338\n",
      "0.22984353\n",
      "0.22214992\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0d9d13797ad4ee4a685c05c4b52d8eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3018), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21001506\n",
      "0.21124262\n",
      "0.22130753\n",
      "0.21488643\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e56fc4796ed4cfab775c280fdec0bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3018), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19880337\n",
      "0.20221686\n",
      "0.21486372\n",
      "0.20933035\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381df121637a44629dbf312e0ce5c093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3018), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19026527\n",
      "0.19532004\n",
      "0.20991637\n",
      "0.20304029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20063902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1987208\n",
      "0.1953579\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2be0b47c4c4f779a076e15b7604eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3018), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16863506\n",
      "0.1775159\n",
      "0.19717997\n",
      "0.19406843\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af35b19c8653443fb4bea56a757ee5dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3018), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16652526\n",
      "0.17574568\n",
      "0.19593714\n",
      "0.19304778\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4234e05b7c3e4f5da7268c35f7f2f4e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3018), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1648\n",
      "0.17429845\n",
      "0.19493139\n",
      "0.19223946\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575d46b511204d8a944e96669ad316dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3018), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16337816\n",
      "0.17310905\n",
      "0.19411533\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62d8dd564d74557ad7e3cd1d69c4a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3018), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16219778\n",
      "0.19211102\n",
      "0.19012849\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e3bbd07b5745439199a5ac8629b535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3018), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15907863\n",
      "0.1695878\n",
      "0.19181754\n",
      "0.18993494\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfaad406478d4786897142383946205f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3018), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15856524\n",
      "0.16918631\n",
      "0.18978496\n",
      "0.16884704\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    count = 0\n",
    "    for b in tqdm(range(total_batches)):\n",
    "        offset = (b * batch_size) % (train_adj.shape[0] - batch_size)\n",
    "        batch_x = train_adj[offset:(offset + batch_size), :].todense()\n",
    "        _, c = sess.run([optimizer, cost_function],feed_dict={X: batch_x})\n",
    "        if count%1000==0:\n",
    "            print(c)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_prediction(user_id_list, item_id_list):\n",
    "    inputUser = train_adj[user_id_list].todense()\n",
    "    rec = sess.run(d4, feed_dict={X: inputUser})\n",
    "    prediction = [rec[i, item_id_list[i]] * 5 for i in range(rec.shape[0])]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572b193c9ed746d5829e1fa85a6865ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8899), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-56:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ben/anaconda2/envs/tensorflow/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ben/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/ben/anaconda2/envs/tensorflow/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "batch_size = 100\n",
    "#test_df.shape[0]\n",
    "for i in tqdm(range(0, len(test_df['reviewerID']), batch_size)):\n",
    "    predicted = get_test_prediction(list(test_df['reviewerID'][i:i+batch_size]), list(test_df['asin'][i:i+batch_size]))\n",
    "    predictions.extend(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder RMSE: 1.0436943563799241\n"
     ]
    }
   ],
   "source": [
    "print(\"Autoencoder RMSE: {}\".format(np.sqrt(mse(test_df['rating']*5, predictions))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the autoencoder outperformed the RBM, but still came in behind the SVD. Again, this is probably a case where tuning the neural network could result in better performance, but just taking the algorithms off the shelf, the simpler method seems to perform better.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This project set out to compare the performance of several algorithms at generating recommendations for Amazon users. The goal is to take past user ratings, and predict ratings on new items, in the form of a holdout test set. Performance is measured by the root mean squared error of the predicted versus actual values on the test set. Starting with a simple baseline of guessing the mean by user or item, I compare the performance of linear regression, collaborative filtering, singular value decomposition, a restricted Bolztmann, and an autoencoder. The performance of each is given below:\n",
    "\n",
    "| Algorithm | RMSE |\n",
    "| --- | --- |\n",
    "| Overall mean | 1.0578 |\n",
    "| User mean | 1.0100 |\n",
    "| Item mean | 0.96592 |\n",
    "| Linear regression | 0.92721 |\n",
    "| Linear regression with interactions| 0.92343 |\n",
    "| Collaborative filtering| 0.93507 |\n",
    "| Singular value decomposition| 0.69514 |\n",
    "| Restricted Boltzmann machine| 1.12856 |\n",
    "| Autoencoder| 1.04369 |\n",
    "\n",
    "The singular value decomposition performed the best. This method was also one of the more efficient algorithms to implement, taking only a few minutes to process. Linear regression and collaborative filtering both outperformed the baseline, but performed far below SVD. The two neural network methods performed slightly worse than the baseline method. However, neural networks take much more work to properly tune, and did show training improvement on the data, suggesting that with further parameter tuning, their performance can likely be significantly improved.\n",
    "\n",
    "Probably the greatest challenge with this project was actually dealing the the size of the data. In a sparse matrix form, the ratings data was only about 155 MB uncompressed. But this same data in the dense form often used by these algorithms, would take up many terabytes. This created certain difficulties. In particular, collaborative filtering normally creates a matrix of all similarities at once, which is how the scipy algorithms are built. In this case, using the premade method wasn't feasible. Instead, a method of only calculating the similarities needed for a given prediction had to be written. Luckily, scipy has recently included sparse matrix support for singular value decomposition. In the neural network cases, it was necessary to convert small portions of the training sparse matrix into a dense matrix for batch gradient descent. This worked, but greatly reduced performance, because it meant a lot of time prepping data, and very low GPU utilization. Tensorflow has begun to implement some sparse matrix support, so going forward using neural networks for these data might become more feasible.\n",
    "\n",
    "As it stands now, there are a number of additional parameter tunings that can be done to improve these algorithms, but in terms of out of the box performance, SVD by far the best choice both for speed and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
